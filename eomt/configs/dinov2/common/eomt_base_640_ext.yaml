trainer:
  max_epochs: 100
  logger:
    class_path: lightning.pytorch.loggers.wandb.WandbLogger
    init_args:
      resume: allow
      project: "eomt"
      name: "anomaly_ext_eomt_base_640"
model:
  class_path: training.mask_classification_semantic_anomaly.MCS_Anomaly
  init_args:
    num_classes: 2
    attn_mask_annealing_enabled: False
    # Steps removed as they were out of range for short training
    # attn_mask_annealing_start_steps: ...
    # attn_mask_annealing_end_steps: ...

    # Learning parameters (important for fine-tuning)
    lr: 1.0e-3  # Low LR to preserve semantic knowledge
    weight_decay: 0.05
    poly_power: 0.9
    warmup_steps: [100, 200]  # Reduced for small dataset (80 samples)

    # Loss coefficients
    mask_coefficient: 2.0
    dice_coefficient: 4.0
    class_coefficient: 4.0

    # Checkpoint loading (CRITICAL!)
    ckpt_path: null  # Will be passed via CLI --model.ckpt_path
    load_ckpt_class_head: true  # Load frozen class_head for prototypes
    delta_weights: false

    network:
      class_path: models.eomt_ext.EoMT_EXT
      init_args:
        num_classes: 19
        num_q: 100
        masked_attn_enabled: False # Force Global Attention to find anomalies
        num_blocks: 3
        encoder:
          class_path: models.vit.ViT
          init_args:
            backbone_name: vit_base_patch14_reg4_dinov2
data:
  class_path: dsets.training_anomaly.GenericAnomalyDataset
  init_args:
    img_size: [ 1024, 1024 ]
    batch_size: 1
    num_workers: 4
    val_split: 0.2  # 80% train, 20% val
    datasets:
      - name: RoadAnomaly
        root: eomt_trained_model/Validation_Dataset/RoadAnomaly
        images_dir: images
        masks_dir: labels_masks
        image_glob: "*.jpg"
        mask_ext: "png"
        gt_format: binary_any_nonzero_is_ood_void255
        skip_no_ood: false
